{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "hSeGWnvNTOSRtzPOceKmQlcJ",
      "metadata": {
        "id": "hSeGWnvNTOSRtzPOceKmQlcJ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#!pip install -U langgraph langchain_openai langchain_community langchain-google-vertexai langchain-google-genai chromadb langgraph pypdf langchain_google_community unstructured[pdf] streamlit sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OdAPZZo3cLYx",
      "metadata": {
        "id": "OdAPZZo3cLYx"
      },
      "outputs": [],
      "source": [
        "#!sudo apt update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HAwPpMDdcs4b",
      "metadata": {
        "id": "HAwPpMDdcs4b"
      },
      "outputs": [],
      "source": [
        "#!sudo apt install python3-pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6D9wtsNRfel6",
      "metadata": {
        "id": "6D9wtsNRfel6"
      },
      "outputs": [],
      "source": [
        "#!pip3 install --upgrade pip setuptools wheel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4mxaimzgV3Rl",
      "metadata": {
        "id": "4mxaimzgV3Rl"
      },
      "outputs": [],
      "source": [
        "#Libraries to be installed in addition on GCP\n",
        "#!sudo apt-get update\n",
        "#!apt-get install poppler-utils\n",
        "#! apt install tesseract-ocr\n",
        "#! apt install libtesseract-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r2UGu6YxlfAf",
      "metadata": {
        "id": "r2UGu6YxlfAf"
      },
      "outputs": [],
      "source": [
        "#!python --version"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "k8aXJzC-LZ7Z",
      "metadata": {
        "id": "k8aXJzC-LZ7Z"
      },
      "source": [
        "#Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "QvTnKRoxLP1Z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvTnKRoxLP1Z",
        "outputId": "7b1e5189-cb1e-4459-95e6-d35385819992"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.cloud import bigquery\n",
        "import sqlite3\n",
        "#import streamlit as st\n",
        "from langchain_community.tools.sql_database.tool import (\n",
        "    InfoSQLDatabaseTool,\n",
        "    ListSQLDatabaseTool,\n",
        "    QuerySQLCheckerTool,\n",
        "    QuerySQLDataBaseTool,\n",
        ")\n",
        "from langchain_community.utilities.sql_database import SQLDatabase\n",
        "from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit\n",
        "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
        "from langchain_google_vertexai import ChatVertexAI\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_community.document_loaders import WebBaseLoader, PyPDFLoader\n",
        "from langchain_google_community import GCSDirectoryLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain_core.messages import BaseMessage, HumanMessage\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain.agents import AgentType, Tool, initialize_agent, AgentExecutor\n",
        "from typing import Union, Sequence, TypedDict, Annotated, List, Dict, Optional,Tuple\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from typing_extensions import TypedDict, Literal\n",
        "import functools\n",
        "import operator\n",
        "from langgraph.graph import END, StateGraph, START, MessagesState\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fbY4vgSJ6gd",
      "metadata": {
        "id": "7fbY4vgSJ6gd"
      },
      "source": [
        "# Load Non-Structured Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "HHrSUa6dMbs6",
      "metadata": {
        "id": "HHrSUa6dMbs6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()  # Load environment variables from .env file\n",
        "\n",
        "api_key = os.getenv(\"GOOGLE_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3D_SCRrWJ_Yg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D_SCRrWJ_Yg",
        "outputId": "dada6b7d-fccf-429b-adff-389034b43a13"
      },
      "outputs": [],
      "source": [
        "#Load from a GCS bucket\n",
        "#pip install --upgrade --quiet  google-cloud-storage\n",
        "#from langchain_community.document_loaders import GCSDirectoryLoader\n",
        "#loader = GCSDirectoryLoader(project_name=\"YOUR PROJECT\", bucket=\"YOUR GCP BUCKET\", prefix=\"PREFIX\")\n",
        "#documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "a37e14c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Load from local\n",
        "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
        "loader = PyPDFDirectoryLoader(\"./knowledge_base/\")\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "mp1Emfh6fs7X",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mp1Emfh6fs7X",
        "outputId": "b7174836-e889-4bd0-9692-a1b48b76acab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "125\n"
          ]
        }
      ],
      "source": [
        "def split_docs(documents,chunk_size=1000,chunk_overlap=200):\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "  docs = text_splitter.split_documents(documents)\n",
        "  return docs\n",
        "\n",
        "docs = split_docs(documents)\n",
        "print(len(docs))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "pZDfneYHcy7q",
      "metadata": {
        "id": "pZDfneYHcy7q"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "persist_directory = \"chroma_db\"\n",
        "#embeddings= GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "embeddings = VertexAIEmbeddings(model_name=\"text-embedding-005\")\n",
        "\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=docs, embedding=embeddings, persist_directory=persist_directory\n",
        ")\n",
        "\n",
        "retriever = vectordb.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "qYZoaYURcr9S",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYZoaYURcr9S",
        "outputId": "10fdbf65-180e-434b-b7c0-1a32ce0cea3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# New\n",
        "question = \"what are the dimensions of the refridgerator?\"\n",
        "docs = vectordb.similarity_search(question)\n",
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "nqFZmsFZdS-H",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqFZmsFZdS-H",
        "outputId": "34f91d5e-b78e-46f7-e71d-705c15db0c27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'page': 0, 'page_label': '1', 'source': 'knowledge base\\\\FRFS2823A_EN.pdf'}, page_content='Refrigerator\\nAdjustable Temperature Drawer No\\nAir Filter Yes\\nCrisper Color Clear\\nDairy Bin No\\nDeli Drawer Yes\\nDoor Bin Color Clear\\nHumidity Controls Manual\\nInterior Lighting LED\\nProduce Keeper Ready Yes\\nProduce Keeper Included No\\nShelf Material Glass\\nWater Filter Yes\\nNumber of Adjustable Gallon Plus Door Bins 3\\nNumber of Fixed Condiment Door Bins 3\\nNumber of Fixed Gallon Plus Door Bins 1\\nNumber of Other Door Bins 2\\nTotal Number of Door Bins 9\\nNumber of Adjustable Shelves 2\\nNumber of Fixed Shelves 1\\nNumber of Crispers 2\\nIce Maker\\nIce Maker Yes\\nIce Maker Location Fresh Food Section\\nSecond Ice Maker Optional\\nExterior\\nCounter-Depth No\\nDoor Finish Smooth\\nDoor Stops Yes\\nFront Rollers Yes\\nRear Rollers Yes\\nElectrical Specifications\\nAmps @ 120 V olts 3.3 Amps\\nMinimum Circuit Required 15 Amps\\nPerformance Certifications and Approvals\\nENERGY STAR Certified Yes\\nProduct Specifications\\nFor planning purposes only.  We reserve the right to change specifications or discontinue models without notice.')"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# New\n",
        "docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "ug8KHrABmAY4",
      "metadata": {
        "id": "ug8KHrABmAY4"
      },
      "outputs": [],
      "source": [
        "# Convert loaded documents into strings by concatenating their content\n",
        "# and ignoring metadata\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "k4F996YvLeAD",
      "metadata": {
        "id": "k4F996YvLeAD"
      },
      "source": [
        "# Load Structured Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "rLHKQjzOJ4U1",
      "metadata": {
        "id": "rLHKQjzOJ4U1"
      },
      "outputs": [],
      "source": [
        "#client = bigquery.Client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "G1nt4wP0Li2o",
      "metadata": {
        "id": "G1nt4wP0Li2o"
      },
      "outputs": [],
      "source": [
        "#QUERY1 = (\n",
        "#'''\n",
        "#SELECT * FROM\n",
        "#'''\n",
        "#)\n",
        "#df_c = client.query_and_wait(QUERY1).to_dataframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "3p7h4Ko4LqtQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "3p7h4Ko4LqtQ",
        "outputId": "0f4fc98f-67ca-4934-bcbc-da1057a99374"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"./knowledge_base/LG_refrigerator_sales.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "2yF8UQX-OJFI",
      "metadata": {
        "id": "2yF8UQX-OJFI"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Brand</th>\n",
              "      <th>Model</th>\n",
              "      <th>Country</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LG</td>\n",
              "      <td>GL-D241APZY</td>\n",
              "      <td>USA</td>\n",
              "      <td>2022</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LG</td>\n",
              "      <td>GL-I292RPZL</td>\n",
              "      <td>Canada</td>\n",
              "      <td>2023</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LG</td>\n",
              "      <td>GL-I292RPZL</td>\n",
              "      <td>Australia</td>\n",
              "      <td>2024</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LG</td>\n",
              "      <td>GL-S292RDSY</td>\n",
              "      <td>India</td>\n",
              "      <td>2020</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LG</td>\n",
              "      <td>GL-D241APZY</td>\n",
              "      <td>Australia</td>\n",
              "      <td>2022</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Brand        Model    Country  Year  Month  Day\n",
              "0    LG  GL-D241APZY        USA  2022      2    9\n",
              "1    LG  GL-I292RPZL     Canada  2023      8    5\n",
              "2    LG  GL-I292RPZL  Australia  2024     11    3\n",
              "3    LG  GL-S292RDSY      India  2020      1   26\n",
              "4    LG  GL-D241APZY  Australia  2022      5    4"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OIIFw-8-UiWx",
      "metadata": {
        "id": "OIIFw-8-UiWx"
      },
      "source": [
        "# Inject DataFrame into DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "fEpACRlsUjyx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEpACRlsUjyx",
        "outputId": "00434d65-41ca-4f66-b883-55368dbfb371"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<sqlite3.Cursor at 0x24f165126c0>"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "connection = sqlite3.connect(\"sales.db\")\n",
        "connection.execute(\"DROP TABLE sales\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "kMAGW7NjU06z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMAGW7NjU06z",
        "outputId": "9a7f15bf-329e-4448-de7c-6a07521dac05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.to_sql(name=\"sales\", con=connection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "0me81ZUtU50k",
      "metadata": {
        "id": "0me81ZUtU50k"
      },
      "outputs": [],
      "source": [
        "db = SQLDatabase.from_uri(\"sqlite:///sales.db\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "Gf1rgNXV75vf",
      "metadata": {
        "id": "Gf1rgNXV75vf"
      },
      "outputs": [],
      "source": [
        "#llm = ChatVertexAI(model=\"gemini-1.5-flash-002\")\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-002\", temperature=0.1)\n",
        "#llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-exp\", temperature=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "VC8yD0Y75j7d",
      "metadata": {
        "id": "VC8yD0Y75j7d"
      },
      "outputs": [],
      "source": [
        "toolkit = SQLDatabaseToolkit(db=db, llm=llm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fJnqkFB-oMU",
      "metadata": {
        "id": "4fJnqkFB-oMU"
      },
      "source": [
        "# Set-up SQL Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "aEUvVntR817b",
      "metadata": {
        "id": "aEUvVntR817b"
      },
      "outputs": [],
      "source": [
        "MSSQL_AGENT_SUFFIX_WITH_MEMORY= \"\"\"While generating SQL for the above query, pay attention to the below:\n",
        "\n",
        "\n",
        "\n",
        "- General Instructions:\n",
        "\n",
        "  - Do not use any LIMIT statements in SQL.\n",
        "  - Round answers to two decimal places.\n",
        "  - Avoid complicated SQL queries such as those involving division within a query.\n",
        "  - Perform operations step by step.\n",
        "  - Pay attention to all conditions mentioned in the query. Do not infer conditions.\n",
        "  - For questions on share or market share, use column=\"Amount\" unless stated otherwise explicitly.\n",
        "  - YTD or ytd = Year to Date\n",
        "   - Don't assume year as current year unless indicated so. Take data for all years unless its indicated to use a specific year\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "PNKiQu2F5sYF",
      "metadata": {
        "id": "PNKiQu2F5sYF"
      },
      "outputs": [],
      "source": [
        "sql_agent_executor = create_react_agent(llm,tools=toolkit.get_tools(),state_modifier=MSSQL_AGENT_SUFFIX_WITH_MEMORY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "Ipfr4DG69Dha",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ipfr4DG69Dha",
        "outputId": "397af683-489d-4fa6-d4cb-57ef0940449f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "How many sales are there in the databases?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  sql_db_list_tables (bf612da9-6e50-411a-8c60-4947ce8258cc)\n",
            " Call ID: bf612da9-6e50-411a-8c60-4947ce8258cc\n",
            "  Args:\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: sql_db_list_tables\n",
            "\n",
            "sales\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  sql_db_schema (2d6857bd-29a3-456c-80b7-f805f9eff507)\n",
            " Call ID: 2d6857bd-29a3-456c-80b7-f805f9eff507\n",
            "  Args:\n",
            "    table_names: sales\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: sql_db_schema\n",
            "\n",
            "\n",
            "CREATE TABLE sales (\n",
            "\t\"index\" INTEGER, \n",
            "\t\"Brand\" TEXT, \n",
            "\t\"Model\" TEXT, \n",
            "\t\"Country\" TEXT, \n",
            "\t\"Year\" INTEGER, \n",
            "\t\"Month\" INTEGER, \n",
            "\t\"Day\" INTEGER\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from sales table:\n",
            "index\tBrand\tModel\tCountry\tYear\tMonth\tDay\n",
            "0\tLG\tGL-D241APZY\tUSA\t2022\t2\t9\n",
            "1\tLG\tGL-I292RPZL\tCanada\t2023\t8\t5\n",
            "2\tLG\tGL-I292RPZL\tAustralia\t2024\t11\t3\n",
            "*/\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  sql_db_query (02fa5137-10cb-47e2-9c1a-0b3bafdd3bb1)\n",
            " Call ID: 02fa5137-10cb-47e2-9c1a-0b3bafdd3bb1\n",
            "  Args:\n",
            "    query: SELECT COUNT(*) FROM sales;\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: sql_db_query\n",
            "\n",
            "[(10000,)]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "There are 10000 sales in the database.\n"
          ]
        }
      ],
      "source": [
        "#Test a qeury with the SQL agent\n",
        "query=\"How many sales are there in the databases?\"\n",
        "\n",
        "events = sql_agent_executor.stream(\n",
        "     {\"messages\": [HumanMessage(content=query)]},\n",
        "     stream_mode=\"values\",\n",
        ")\n",
        "\n",
        "for event in events:\n",
        "   event[\"messages\"][-1].pretty_print()\n",
        "   message_content= event[\"messages\"][-1].content\n",
        "   if \"Answer:\" in message_content:\n",
        "      final_answer=message_content.split(\"Answer:\",1)[1].strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ikWfsjEw-sL1",
      "metadata": {
        "id": "ikWfsjEw-sL1"
      },
      "source": [
        "# Set-up RAG Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "eTV3vToePeKy",
      "metadata": {
        "id": "eTV3vToePeKy"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_PROMPT = \"\"\"\n",
        "CONTEXT:\n",
        "{context}\n",
        "\n",
        "QUERY:\n",
        "{question}\n",
        "\n",
        "Use only the provided context information to form your response. If an answer can not be found within the provided context information respond with 'The answer could not be found in the provided context.\".\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "f_CVgKq6LLq4",
      "metadata": {
        "id": "f_CVgKq6LLq4"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "\n",
        "#rag_chain = (\n",
        "#    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
        "#    | rag_prompt | llm | StrOutputParser()\n",
        "#)\n",
        "\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | rag_prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "xMxjk05dLanK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xMxjk05dLanK",
        "outputId": "968ce040-10bf-41c4-8e6c-a38a72a70d33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Height With Hinge: 70\"\\nHeight Without Hinge: 68 3/10\"\\nWidth: 36\"\\nWidth of Cabinet: 35 6/10\"\\nDepth of Cabinet: 28 1/2\"\\nDepth With Door: 33 3/10\"\\nDepth With Door 90Â° Open: 48 1/2\"\\nDepth With Door and Handle: 35 7/10\"'"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_chain.invoke(\"What are the dimensions of the refridgerator?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "r_zJAMCdNdfX",
      "metadata": {
        "id": "r_zJAMCdNdfX"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated, List, Tuple, Union\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def retrieve_information(\n",
        "    query: Annotated[str, \"query to ask the retrieve information tool\"]\n",
        "    ):\n",
        "  \"\"\"Use Retrieval Augmented Generation to retrieve information.\"\"\"\n",
        "  #return rag_chain.invoke({\"question\" : query})\n",
        "  return rag_chain.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "CUdZM-25Ndm-",
      "metadata": {
        "id": "CUdZM-25Ndm-"
      },
      "outputs": [],
      "source": [
        "tools = [retrieve_information]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c_reueFIeCze",
      "metadata": {
        "id": "c_reueFIeCze"
      },
      "source": [
        "# Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "U4VmEoJ7qVCJ",
      "metadata": {
        "id": "U4VmEoJ7qVCJ"
      },
      "outputs": [],
      "source": [
        "## Structured Output Enforcement\n",
        "#class RealterInfoResponse(BaseModel):\n",
        "#    \"\"\"Respond to the user with this\"\"\"\n",
        "\n",
        "#    AGENT_ACHIEVEMENT_DESCRIPTION_AS_WAS: str = Field(description=\"What cap segment the realtor is in\")\n",
        "#    first_name: str = Field(description=\"First name of the realtor\")\n",
        "#    Contacts: float = Field(description=\"Number of contacts\")\n",
        "#    SmartPlans: float = Field(description=\"Usage of smartplans\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-NTlKT_5zKGE",
      "metadata": {
        "id": "-NTlKT_5zKGE"
      },
      "outputs": [],
      "source": [
        "## Structured Output Enforcement\n",
        "#model_with_tools = llm.bind_tools([RealterInfoResponse])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "GHN66A1QDmA_",
      "metadata": {
        "id": "GHN66A1QDmA_"
      },
      "outputs": [],
      "source": [
        "# The agent state is the input to each node in the graph\n",
        "class AgentState(MessagesState):\n",
        "    # The 'next' field indicates where to route to next\n",
        "    next: str\n",
        "    # Structured Output Enforcement\n",
        "    #final_response: RealterInfoResponse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "B3Ij72VceCIp",
      "metadata": {
        "id": "B3Ij72VceCIp"
      },
      "outputs": [],
      "source": [
        "members = [\"PDF_analyst\", \"Sql_agent\"]\n",
        "options = [\"FINISH\"] + members\n",
        "\n",
        "# The agent state is the input to each node in the graph\n",
        "class AgentState(MessagesState):\n",
        "    # The 'next' field indicates where to route to next\n",
        "    next: str\n",
        "\n",
        "\n",
        "def make_supervisor_node(llm: llm, members: list[str]) -> str:\n",
        "    options = [\"FINISH\"] + members\n",
        "    system_prompt = (\n",
        "        \"You are a supervisor tasked with managing a conversation between the\"\n",
        "        f\" following workers: {members}. Given the following user request,\"\n",
        "        \" respond with the worker to act next. Each worker will perform a\"\n",
        "        \" task and respond with their results and status. When finished,\"\n",
        "        \" respond with FINISH.\"\n",
        "    )\n",
        "\n",
        "    class Router(BaseModel):\n",
        "        \"\"\"Worker to route to next. If no workers needed, route to FINISH.\"\"\"\n",
        "\n",
        "        #next: Literal[\"FINISH\",\"PDF_Analyst\",\"Sql_agent\"]\n",
        "        next: Literal[(*options,)]\n",
        "\n",
        "    def supervisor_node(state: MessagesState) -> MessagesState:\n",
        "        \"\"\"An LLM-based router.\"\"\"\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "        ] + state[\"messages\"]\n",
        "        response = llm.with_structured_output(Router).invoke(messages)\n",
        "        next_ = response.next\n",
        "        if next_ == \"FINISH\":\n",
        "            next_ = END\n",
        "\n",
        "        return {\"next\": next_}\n",
        "\n",
        "    return supervisor_node"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jiGPaxUuA3Rd",
      "metadata": {
        "id": "jiGPaxUuA3Rd"
      },
      "source": [
        "# Initialize the Research Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "apsqa8ePB9nB",
      "metadata": {
        "id": "apsqa8ePB9nB"
      },
      "outputs": [],
      "source": [
        "rag_agent = create_react_agent(llm, tools=tools, state_modifier=\"You should provide RAG search.\")\n",
        "#rag_node = functools.partial(agent_node, agent=rag_agent, name=\"PDF_analyst\")\n",
        "\n",
        "def rag_node(state: AgentState) -> AgentState:\n",
        "    result = rag_agent.invoke(state)\n",
        "    return {\n",
        "        \"messages\": [\n",
        "            HumanMessage(content=result[\"messages\"][-1].content, name=\"PDF_Analyst\")\n",
        "        ]\n",
        "    }\n",
        "\n",
        "\n",
        "sql_agent = create_react_agent(llm, tools=toolkit.get_tools(), state_modifier=MSSQL_AGENT_SUFFIX_WITH_MEMORY)\n",
        "#sql_node = functools.partial(agent_node, agent=sql_agent, name=\"Sql_agent\")\n",
        "def sql_node(state: AgentState) -> AgentState:\n",
        "    result = sql_agent.invoke(state)\n",
        "    return {\n",
        "        \"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=\"Sql_agent\")]\n",
        "    }\n",
        "\n",
        "research_supervisor_node = make_supervisor_node(llm, [\"PDF_Analyst\", \"Sql_agent\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rXvk3FYTCA6a",
      "metadata": {
        "id": "rXvk3FYTCA6a"
      },
      "source": [
        "# Create the Research Workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "BQa_y5yECCqX",
      "metadata": {
        "id": "BQa_y5yECCqX"
      },
      "outputs": [],
      "source": [
        "research_builder = StateGraph(MessagesState)\n",
        "research_builder.add_node(\"supervisor\", research_supervisor_node)\n",
        "research_builder.add_node(\"PDF_Analyst\", rag_node)\n",
        "research_builder.add_node(\"Sql_agent\", sql_node)\n",
        "\n",
        "# Define the control flow\n",
        "research_builder.add_edge(START, \"supervisor\")\n",
        "# We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
        "research_builder.add_edge(\"PDF_Analyst\", \"supervisor\")\n",
        "research_builder.add_edge(\"Sql_agent\", \"supervisor\")\n",
        "# Add the edges where routing applies\n",
        "research_builder.add_conditional_edges(\"supervisor\", lambda state: state[\"next\"])\n",
        "\n",
        "research_graph = research_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "9QxSp4ddCQ_5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "9QxSp4ddCQ_5",
        "outputId": "cd39b103-cd10-4162-c36b-09503050e47a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAD5CAIAAAABYB27AAAAAXNSR0IArs4c6QAAIABJREFUeJzt3XdcU9f7B/ATEjJI2GEjS5wogkXcogKiiKJUQMVZRx21jvptcdSBo8O27kGdFLdAwQGiIKKguBcWBwoissPI3vn9EX+UKrJMcpPL8375B9zc8SGRh3PvPfccgkKhQAAAgFN6WAcAAAA1ghoHAMAzqHEAADyDGgcAwDOocQAAPIMaBwDAMxLWAdqjqndCHlvGZ8vEIrlIIMc6TotQaHpEIsHAiGhgSLR2omEdB4CWIkD/OI0pesZ//YT7Opdn34km5MkNjIimFmSZVDfefzJNr6ZCzGfLFArFm3/4zj3ozj3o3byNsM4FQDOgxmlC0XP+zXMsph3Z0oHq0oNON9bt5rNcrijI5RXk8gr/4XkHmLkPNsE6EQCfBDVO7S4dKxOwZf3HmFvaU7HOomJSiTz7LOv1E+6omTbWjnj76QA+QI1To5py8fFfi0K+sbNxxvMFLG6tNOVwafd+Rm79jbHOAsCHoMapC48t/Xv3u8nfO+gRCVhn0YQrpyo6dKZ18jTEOggA/wE1Ti3Ki4Rpx8sjIh2xDqJRacfLDU1JfUeZYx0EgH9B/zjVk0rkCTvftbcChxDym2zFKhW/eszFOggA/4Iap3qpf5VHrHDAOgU2Ar+yeX6XU1spxjoIAO9BjVOxJ1l1dGOikZk+1kEw062vUVZiFdYpAHgPapyK3ThfNSCIiXUKLDm70UUCeclrAdZBAEBQ41Ts8fVa7wAzMrW9v6uDxjH/yanDOgUACGqcij27w7HtqKGucDKZ7OHDh1ht3jQrB2rhP3wBV6am/QPQclDjVIbHlnJrpVYOGuruv2HDhs2bN2O1ebOce9ALcnnq2z8ALQQ1TmXe/MPr1k9zz6iLRKK2bajsEdnmzVvI1YNRWgiX5AD2dPvhcK3CKhMbmqjldmpWVtbOnTuLi4ttbW0nTJgQHh6+bt26y5cvI4S8vLwQQmfPnrW1tT179uzp06fz8/MNDAz69++/fPlyU1NThFBaWlpkZORvv/0WGxv79OnT6dOnl5eXf7y5ajMbmuqXFQhVu08A2gBqnMrw2TJ1nKjy+fwffvjBxcVl9erV+fn5lZWVCKGvvvqqvLz83bt3UVFRCCEmk4kQevLkiZOTU2BgYHV19cmTJ3k83rZt2+r388svvyxcuHD+/PkODg5CofDjzVWLbkTkseF6HMAe1DiV4dVJ1TFoUnV1tUgkGj58+KhRo+oXOjg4mJiYsFgsDw+P+oUrV64kEN4/G0sikQ4dOiQSiSgUinJJeHh4UFBQ/cofb65aFBpRJlNIxXISGa6HACxBjVMZoj6BSFT9bu3s7Nzd3Q8ePEij0UJCQshk8qfWlEgkJ0+eTE5OLisro1Kpcrm8pqbG2tpa+aq3t7fqwzXJwJAokyngfxjAFvyNVRkyRY9bp/qzMwKBsGPHjqCgoG3btoWEhNy/f7/R1RQKxZIlSw4dOjR27Nhdu3YFBgYihOTyfwdSNzAwUHm2JkhEcgFXRqGpoeoD0BpQ41TGwIjEZ0vVsWcGgxEZGRkfH89gMJYtW8bn85XLG44Zc//+/du3b0dGRk6ePLlHjx6urq7N7latQ87w2FK6EbThAPagxqmMmbW+RKyWCWiU/Tzs7OwmTpzI5XJLSkoQQjQajcVi1bfUamtrEUJdu3Zt+G3DdtwHPthc5fgcmW1HGBkYYI+4bt06rDPgBJmqd+McS+WTG0gkkpCQkMrKyqqqqlOnTolEogULFpBIJA6Hk5qaWllZyWazy8rK3Nzczpw5U1paSqfTr1y5cuDAAYlE4uXl5eTk9Pr167S0tLCwMBOTf7N9sLmjo4pHgnp4tdbEkmztBGUOYAxqnMrQ6MTH1+s6dDGg0VV5EYrH4xUVFWVkZFy5csXCwmLdunX29vYIIVdX17q6uosXL96/f9/ExGTYsGEuLi7nzp07d+6cVCrduHFjRUXFw4cPg4KCGq1xH2yu8jsSmfGV/QLNqQZwPQ5gDMYBVqW7l6updGKPAe19WoPaSvGN86zAmTZYBwEA+o6olIePyf7VBU3UuJs3b65YseLj5RQK5VMPVx0+fNjZ2VmlMT/E5XIbdp1ryN3d/fHjxx8v/+abbyZMmPCpHd48z+rcGyZ2AFoB2nEqlpPMIpIIfUaYNfqqUCisrq7+eLlYLP5UxzdLS0sSSb1/iuRyeVlZWas2MTIyYjAYjb5UUSTMiKsMX9ZBRekA+CxQ41QvYVfx+AV2BL12MR3XxzJOl3fyNLTvpNHueAB8CvQdUT2fEIsTv73FOgU2ss9WGTPJUOCA9oAap3rmthQvP9Nz+0uwDqJp9zNqeHXS3sNNsQ4CwL/gXFVdSgoE99NqguaoeMwirfXgao2QJ+s/ul3PZQG0ELTj1MXWmdbV2+jo5jdCvloe8NIq6SfLOdVSKHBAC0E7Tr1qKsQZpyss7CkDgphEEg7vQuTerLtxljUomNldg2MgA9ByUOM04eHV2hvnq/qMMLPrSNPYpDZqVVMhLnzK++c229aJNmCsOYwvArQW1DjNeXy99uVDbnWp2K2/kUKB6MYkIzN9pCNtOyKJwGZJeHVSqVhRmMdDCuTkRu85yMjY/JPj2QGgDaDGaZqQL3v7gs+plvLqpDIZ4tWp+Godi8Vis9kqfzTC0FRfLpPTjUkMY5K1E9XUCkob0A1Q4/AmJSUlOzt748aNWAcBQCvAfVUAAJ5BjQMA4BnUOLzR19dXx1yCAOgoqHF4I5FIqqqqsE4BgLaAGoc3enp6VCqMMA7Ae1Dj8EYulwuFQqxTAKAtoMbhDYlEMjSEMXgBeA9qHN5IpVIOh4N1CgC0BdQ4vCGTyZaWllinAEBbQI3DG7FYXFFRgXUKALQF1DgAAJ5BjcMbIpFoYADTKQDwHtQ4vJHJZHw+H+sUAGgLqHF4QyQS6XQ61ikA0BZQ4/BGJpPxeDysUwCgLaDGAQDwDGoc3pDJZDMzM6xTAKAtoMbhjVgsrq6uxjoFANoCahwAAM+gxuENhUKBMTIBqAc1Dm9EIhGMkQlAPahxAAA8gxqHN2Qy2cLCAusUAGgLqHF4IxaLKysrsU4BgLaAGgcAwDOocXgDcw8C0BDUOLyBuQcBaAhqHAAAz6DG4Q3MrwpAQ1Dj8AbmVwWgIahxeKOvrw/jjgBQD2oc3kgkEhh3BIB6UOMAAHgGNQ5viEQig8HAOgUA2gJqHN7IZDIul4t1CgC0BdQ4vCGTyfCcAwD1oMbhjVgshuccAKgHNQ5vYGwlABqCGoc3MLYSAA1BjcMbEolkbGyMdQoAtAVBoVBgnQGoQEhIiEwmk8vlAoFAKpUaGxsrv05LS8M6GgBYImEdAKhGr169kpKS9PTeN8y5XK5CoejUqRPWuQDAGJyr4sTMmTPt7OwaLqFSqeHh4dglAkArQI3DCQcHh4EDBza88mBrazt+/HhMQwGAPahx+DFp0qT6phyFQpkyZQrWiQDAHtQ4/HB0dBw0aJCyKWdraxscHIx1IgCwBzUOV8LDw+3s7MhkckREBNZZANAKcF9VBQQ8GatELBbJsQ6CEGIO/mLCs2fP3F39X+fysA6DiERkakk2MtfHOghov6B/3GeRiuWXj1UUv+R36EIXC7WhxmkXhimp6BnP1EK/zwgz2440rOOA9ghqXNuJBLL4He/6jGRaOxlgnUWriYSySzHv/CZZWnaAyXSApsH1uLY79dvboWE2UOCaRaESx3ztkHKkrLZSjHUW0O5AjWuj3Bt1Lr0MDc3gSlNL9R9jefdSDdYpQLsDNa6NyotENEO4Y9MKxkxy0XM+1ilAuwM1ro0kQrmxGRnrFLrEwJBENSBKxXBnBmgU1Lg2EvBlMvhtbaU6loRAIGCdArQvUOMAAHgGNQ4AgGdQ4wAAeAY1DgCAZ1DjAAB4BjUOAIBnUOMAAHgGNQ4AgGdQ4wAAeAY1DgCAZ1DjAAB4BjWunUpOSRoX4ldeXoZ1EADUC2pcO0UmU+h0hp4e/AcAOAcjoOGWQqFoYpAPP9+Rfr4j1X0UADAHNU5DhELhth0/37hxDSHk7u75zYLl1tY2ixbPolFpv/6yS7nOqdOx+6K3X0zOplAoY4KHdu3iJhAK8vOfGxubBIwImjZ1Don0/vNKOht3+szRqqoKa2tb3+Ejw8OmUiiUurracSF+875e/DL/eXb21Y4dOxUVvenrPWDVyo3KrR4+vLf0u69/2rTt6rW01NTzCKHLqTkkEiknJ+vPAztLSoqtrW3HjpkQMj4cIcRiVe3dt/XW7WypVNqzh8e8r5e4uLgihLbv+CXzWvryZav37Nv67t3bfXtju3Tuht37CkAzoMZpyPETh1NTz8+cMc/cnJl66TyN1vwkVUVvC+fPW8o0t7iZc/3Y8cNcLufbRd8jhI7E/Hkm7mjI+ImOji5v3xaeOv1X8builZFRyq2OHj0YHBz6+2/7iETi5cvJF5L/5vP5BgYGCKHLaclWVtbe3gPMzJlyufzy5WSEEJ/PXxf1g5Ojy3fLVhcU5LNYlcqKvGz5PDa7bu6cb6kU6olTMcuWz4v9629DhiFCiMfjHjy8Z8niSKFQ0LlTV/W/eQC0HdQ4DSktK6HRaJMnzSCRSKMDx7Vkk6E+/kN9/BBCPXr0YrPrzp1PmD79a4lYfOz4odWrNvkM8VWuZm5usXXbT98sXK78tnv3nrNnLVR+TaVQ4xNOXL9+JSAgSCQSXbueHh42TU9Pr3Onrk6OLsp1amqrRSLR4MHD/f1G1R/6clpyUVHh77/t7e3ZByHUs6fn5CljExJOTp82ByEkFouXL1vdrVsPVb9JAKgeXHLWED/fUUKh8IfIRa9f57dhc2/vAVKp9OXLZ/fu3ZJKpZs2rx4xsr/y385dWxBCVZUVyjV79/au38rR0blnT4+09BSEUPaNTKFQGDgq+IM929rYubm5Hz12MD7hpFj8ft6sR4/uMegMZYFDCFlb2zg4OD1/8Y/yWyqVCgUO6Apox2lIX+8BP23evi9626w5E0cHjluyOLL+4lpLMBiGCCGBgM+qrkIIbd60zdLCquEKtrb2PB4XIUSl/ucseMzokJ9/XcdiVV1OSx40cKiZmfkHeyYQCD9v3nHg4K590dvOxB1d8UNUr169uTyusYlpw9WMjIxZVZXKr2k0mG4R6Axox2lOX+8BB/efXDB/6YXkxBMnY5T1pYXbKptpFhZWhoZGyiUODk4N/32qYg4Z4kunMxL+Pnnnzs2xYyc0ug6DwViyODLmSDydzlj94zI+n2/BtGSz6xquU13NUtZZAHQL1DgNUZ4G6unphU6IYDItXr58hhAyMTZVtsuUyspKGt1WoVCkXDxryDB0dHD29OxDIBD+TjxV/6pAIGjiuBQKxd8/8MTJGDu7Dp4eXo2uIxKJlCetIeMncnncsrISNzd3Doedl5erXOHVq5fv3r3t2dOjrT89AJiBc1UNSfj7ZPaNTH+/QBarsqqqskuX7gihPn36X9+acfrMUQ8Prxs3Mi8kJzbcJOPqJXNzJoVCzcxMe/Dw7tdzv6XRaPZ2HULGT4xPOLFy9dJBA4eyWFWJSad/2ry9ifubY0aHJCScHBMU0uirEolk+swvh/r4Ozt1TEo6w6AzbG3tHRycjh0/vC7qh6lTZuvp6cXGHjAxMQ0eG6qGNwYA9YIapyG2tvYSsXjvvq10OiMkZGJ42FSE0KiRY4uLi06e+iv26IEhg33DQqccO364fhMm0zL10vm3b99YWljN+3qxchOE0MIFyywtrf7++9SdOzfNzZmDBw2zYFo2cWgnJxevL/qOGBHU6KsCocDTo09aegqPx3V2dt28aRuVSkUIbfll9569f+zdt1Uul7v39Fy44DtTUzNVvysAqB1BoVBgnUEn/b3nXff+ZrYuzXdza5sxwUMDR42bP2+JmvaPiaMbX83d7ELUh+cigObA9TgAAJ5BjQMA4Blcj9NS55KuYh0BADyAdhwAAM+gxgEA8AxqHNAchUJx+vRpFouFdRDQjkCNA5pDIBCKi4tv3LiBEIqLizt48GBVVVULtgOg7eCeA9CoZcuWKfvHffHFFykpKS9fvmQymTt27JBKpTNnzjQ1NW3BPgBoBahxABvOzs4LFixQfj1u3Ljr16+zWCxTU9MffvjB0NBwyZIlDAYD64wAD+BcFWDPwcEhIiLC1dUVIbR48WI3NzehUIgQioiI+P7776VSKdYBgQ6DGge0i62t7fjx45lMJkJo9+7dAQEByscNBw4cuHz5cuUILhKJBOuYQGdAjQPay8TExNfXV19fHyGUnp4+adIk5QQUgwcPjoyMRAhVV1fX1NRgHRNoNbgeBzTq6dOnNXUsNptdVlZWUlJSXV0tEAhqamrOnDnT9IZUKvWLL75QFr6cnJz8/HyEUGVl5cKFC2fMmDFlypRHjx6ZmZl16NBBUz8K0A1Q49rIiKmPEAzZ0jr6DMHiJd+KxELlqJxKbZuhVXnxrkuXLmlpabW1tQih4uLitWvXLlq0yNfXNycnx8TEpGtXmDMMwLlqW9EMiFXvhFin0CXVZSI6zcjZxUkikRAa0NPT+8zGl4mJCUJo9OjRiYmJgwYNQgjV1dVt2LDhxIkTCKHr16/fu3dPdT8H0DFQ49rIsbsBuwqufLdCeZGgkyfj0KFDHTt2bLhcJpPt3btXVUehUCgIoYCAgGPHjoWGhiKE5HJ5dHT07du3EULHjx+/fv06jJnYrsAYmW2Xk8zi1Mj6BTU1Bi9QKvyHk5dTG7a0A0KIzWZPnz797du3ypcoFIqpqam9vf3YsWMDAwPVGiMpKSkjI2PVqlUWFha7du3q1q3bsGHD9PTgLz2eQY37LHfTasqLRLYdDZh2VH0y/Kp8SIFQdamQUy15k8cNW2pff92tpKRkwYIFxcXFCKG7d+8ihO7cuXP27NlLly6NHTs2ODi4Rw+1z9+amJh448aNFStWmJqa7tixw9XVVd0VFmACalzbxcfHx8fH/7Rm/4t7XAFXVl0m1sxxxSKR4v9Pyj4mk8nkcrmyvwXmmHYUhJBDF5r7YJMPXsrNzf3+++/Lysru379fv1AqlZ49ezYpKYnH4wUHB48dO9bY2FgDOS9fvnzt2rV169bxeLw//vjDx8dn2LBhGjgu0ACocW1RUlJia2u7d+/e6dOnGxhodELlnTt3nj9/3sHBYf/+/Y2ukJKSkp2dvXHjRk2mapucnJy1a9empqZ+/FJBQUFSUtKjR49MTU2Dg4N9fHw0E0kul1+4cKGoqGjhwoXPnj07fvz4qFGj+vfvr5mjA3WAGtc6jx8/XrhwYWxsrJOTk+aPvmHDhoyMjNraWjc3t9jY2EbXKS4urqys9PT01Hg6tcjMzExKSnrw4IHyHNbFxUVjh5ZIJJcuXaqpqZkyZcq9e/cSEhKCgoKg3ukcqHEtdeXKleHDh+fk5Li7u2u47aa0ePHie/fuCYVChULh4uLSbKdZPGGz2cpzWCMjI+U5rIYDiMXiK1eu1NXVhYeHX7ly5erVq2FhYRq4aAg+H9S4Flm0aJG/v7/mf7WU2Gz24sWL8/Ly6p9Ot7S0jIuLa7TUPnnypKioaPTo0RqPqQlPnjxJSEhITk4eN25cSEhIly5dNJ9BKBSmp6eTSKSAgIATJ068fPly2rRpmLTrQUtAjWtKbGysiYnJmDFjhEKhcmZlTEyePPn58+cNHwawtLQ8dOiQtbX1xyunpqZmZmZu3rxZsxk1SiqVJiYmJiQkEInE0NBQrP72IIQ4HM6VK1csLS379++/a9cuLpc7e/Zs5YACQEtAjfuklJSU58+fL1q0iEgkYptk7NixJSUlDZfY2Nj89ttvjbZi2Gw2m822t7fXYEDM/PPPP4mJiWfPng0NDQ0NDXVwcMAwTFVVVUZGRvfu3d3c3H7++WcDA4OvvvoKRsHDHNS4D8XFxWVnZ2/dulUqlZJIWvQ8b1FR0YQJE2QyGYFAYDKZmzZtUj6jDiQSyZkzZ86cOWNjYxMWFjZ06FCsE6GioqKMjAwfHx8nJ6f169c7ODhMnTpVq/47tR9Q4/4lEomKiori4uIWL16MyV2Fpv3+++82NjaTJ08eNWoUh8PJyspqdLWCgoKrV6/OnDlT4wGxd+vWrdOnT8tkst69e0+ZMkVLHmB48uRJZmbm5MmTzczM1qxZ4+XlheHJdXukAApFXl5eSEgIh8ORSCRYZ/mkUaNGSaXSZld78eJFeHi4RhJpqaqqqm3btnl5eW3ZsqW0tBTrOP+RkZHx008/KRSKmpqaX3/99d69e1gnwr/23o5T9uY9fvz4gAEDtPnWWEJCQmFh4bJly5pdUyKRvHjxws3NTSO5tNqJEyeOHj3q5uYWERHRq1cvrOP8h0wmO3PmTGFhYWRk5IsXL27dujVixAgrKyusc+FQ+61xEolk9erV3bt3nz59OtZZmjd69OiDBw82eiMVNC09Pf3YsWPm5uYTJkzo27cv1nEaweFwDh48iBBasmTJ48ePWSzW4MGD4eKdqrTTGieXy1+/fl1YWOjn54d1luZdvHjx1q1ba9eubeH6UVFRc+fOhYLYUG5u7p49ewQCwdy5c7X5WYU3b97s3LnT1tZ22bJlubm5hoaGjo6OWIfScVifLGtadnb2wIED5XI51kFaYcyYMcXFxS1ff8WKFRcvXlRnIl316NGjhQsXTps2LTs7G+sszcvJyRk/fvy5c+cUCsXLly+xjqOr2lE7jsVimZubx8TEhIWF0Wg0rOO0VEJCQl5e3qpVq1q+SUlJiVwubydd5NogNzc3Ojra1NT0yy+/1LbrdB/jcrkMBuPQoUMHDhw4fvy4k5MTtj3SdU57qXG///67vb19eHg41kFabcaMGbt27YKupCr37NmzX3/91crKavny5ebm5ljHaZ5IJBIIBCYmJsHBwba2tjt27NCSEbS0nFZ0IFIroVD4/PlzGxsbXSxwW7du9fPza0OBmzp1qkAgUE8onOjateuhQ4eGDRs2adKkXbt2YR2neRQKRTlzRVJS0syZM2UyGUJo5syZhw8fxjqaVsN5jVu7di2fz+/UqdPkyZOxztJqb9++ffPmzZQpU9qwraOj49WrV9UQCm9GjBhx6dIlOp0+aNCgS5cuYR2npby9vZWnq5GRkcpJzlgs1p49e5RDK4OG8HyuevjwYQsLi6CgIKyDtNHEiRM3bNjQqVOnNmwrFAoFAoGpqakacuGTQCA4cOBAUVHRli1bsM7SFlKpNCYmpqioaP369c+ePSOTyZoca0+rYX3TQy1OnTqlUCjEYjHWQdpu37590dHRn7OHljwUAT6Qnp7u7e2dlZWFdZDPkpeXN2HChMuXLysUitraWqzjYAyH56rffvut8gKW7l6RffHixZs3b+bOnfs5Ozl48GB0dLTqQrULw4cPz87OPnXqlE4PTtW1a9czZ854e3sjhI4ePTpnzpyioiKsQ2EGV+eqFRUVlpaWz58/x2ToRBXq27dvdnb2Z/Z0F4lES5cu3bNnj+pytSPx8fEZGRk6cS+iWffv3ycSib169YqJienSpUu/fv2wTqRR+Klx6enpHA5n3LhxWAf5XHPnzv36669h3CTMvXnzZuHChefPn8c6iMo8ePDgwIEDq1atMjMz43K57WQsT/ycq2ZlZeGgwO3atcvPz0+FBe7EiROq2lV74+jouH//fl9fX6yDqIynp+fu3buVT/5HREQcO3YM60SagIcax2KxqqqqWv44p9Y6duyYWCwOCwtT4T6NjY1x8M5gxcbGJj4+ftq0acrOaPhAJBKpVGpqaqryT+m1a9cSEhKwDqVGOl/j4uLi/vzzTxy0ujMyMh4/ftyS0ZNaJTAwMDQ0tLa2VrW7bT9MTEwWL148Z84crIOoXteuXRFCvXv3zsvL2717t3IwHqxDqZ5uX4+rqKgoLy/v2bMn1kE+1+3btw8fPrx371417b+4uBgeX/0csbGxVCo1NDQU6yDqohzZPyoqisFgLF26tOEESbpOh9txyon4oMC1BIfDadvzEkApNDR027ZtWKdQI+VN/DVr1lhZWfF4vOLiYtycnhPXrVuHdYY2mjVrVs+ePXV96NRTp05lZmZu3bpVrUexsLDw9PR89eqVra2tWg+EVyQSqby8nM1md+7cGess6uXu7k4mkwUCga+vb9euXXEwep2utuMePHgQERHh7u6OdZDPkpSU9OrVK810N3V2du7Vq1f9LNSgtQYOHPj06VOsU2iIlZXV7du3lcM6PH/+HOs4n0VXa5ynp6dODOHbhCNHjjx69GjlypUaO6K+vv7WrVtPnjypsSPiCZPJzM3NxTqFRo0YMUI53N7SpUuxztJ2OlnjHjx4kJaWhnWKz3LgwAEOh7NmzRoNH/d///ufq6trQUGBho+LA4aGhmZmZlinwMCXX345fvx4mUz29u1brLO0hU7WuG3btun0ZAXffPMNk8lctGgRJkf38vJydnZOT0/H5Oi6q66uDk93G1tlyJAhRCKxrq7u+++/xzpLq+lejePxeHPnzu3RowfWQdpCIpGMGTMmIiIC80cyWCzWhQsXsM2gW54+fdrO79j06NEjICAgPT1dt67q6l6No9PpAwcOxDpFW+Tm5s6ePTs6Olob5oUKCwuD2e1apbCwcPDgwVinwJivr6+Pj09VVdWtW7ewztJSulfj/vrrr9TUVKxTtFp8fPyWLVtiYmK0py0QEBCAEPr555+xDqIDKisr8/Ly2tuIHY0ikUjW1tYxMTFlZWVYZ2kR3atxT5480bmB4TZs2PD8+fOYmBisgzRi3Lhx3377LdYptF10dDTmlxe0yp49e3TlAUHde5br6dOnjo6OujJPlUAgWL58ub+/vzb/hrDZbCMjo4KCAmdnZ6yzaKOCgoIdO3aou5+2Ljp79mz37t1dXV2xDtIU3WvHubm56UqBu3nzpr+//5IlS7S5wCGEjIyMlONPxMbGYp1FG+3du3fJkiVYp9BqXaj+AAAZs0lEQVRGY8eO3bJlS2lpKdZBmqJ7Ne6PP/54+PAh1imad+zYsWPHjmVlZbVt0hnNmz59ulAoxDqF1tm0aZOPjw8OHmlSk+joaBsbG6xTNEX3apxIJMrPz8c6RVNkMtmsWbNIJJLOjZStHEEoOjr62bNnWGfRCjExMYaGhqNHj8Y6iFYrKCh49OgR1ik+SfeuxxUXF8vlcgcHB6yDNO7+/fvz5s37888/PTw8sM7SRhKJZMaMGTt27NCJ2ePV5/Tp08XFxSof0Q+XRo4cGRsba2FhgXWQRuhejVPeCpRKpbW1tVKpNCcnB+s4/9qxY0d1dbXuDuXSUHl5uZ6enrm5uZ6e7jX2P190dLSzs7PygU3QrNLS0tra2m7dumEdpBE60wt00qRJBQUFyjlD6x+p0Z6+ZtXV1QsXLhw5ciRu+mFYWVkJhcK+ffumpKTUD7M8cuRIKpWamJiIdTr12r59u56eHhS4lrOxsdHaq3I68yf6xIkTymdU6wucXC43NjbGOhdCCJ0/fz4qKmr9+vXTp0/HOosqUanUO3fuvH37VjnGTkhISFVVVWVl5fHjx7GOpkYrV640NTXF6mli3bVlyxbtHHtKZ2ocQmjy5MkNrxARCATlLLnYWrly5Z07d7Zt24bX0RM9PT319PSCg4PfvHmjvOcTFxenrHo4I5FI5s6dGxAQMG3aNKyz6B4KhXL37l2sUzRCl2pcWFiYj49P/UMOJiYm2E5C+vjxYx8fHx8fn/Xr12MYQwMoFAqbza5vQZeXlx85cgTrUCqWm5s7adKkH3/80cfHB+ssOik8PFw7JwXWmetxSitXrnz58uWTJ08QQgwGo3v37lgl2bdv361bty5cuKArHZI/R3BwMIfDqf9WJBKlpaWFh4fjZjy1hISEpKSkuLg4rIPoMCsrK+2ceECX2nFKmzZt6tixo0KhcHR0NDEx0XyA2traadOmEYnEw4cPt4cChxBSDo7Y8BZ8cXExbmYg/umnn/Ly8rTzaWIdkp+fv337dqxTNKJF7TipRC7gytUfpkUMaZZzv1q8a9eu/n2Gc2o0PY7VnTt3tm7dum7dus6dO7f26IamOtZq5tZKlWVtxpT5+fn5LBZLJpPx+XwOh6NQKK5n3A3wfau1d9NaaPny5cOHDw8MDGz20yQQEMNExz5BTeLz+YWFhVinaEQz/ePybrMfX6+rLhPTGEQNptJeIpGIQqG0YUOmHeVdPt/VgzEomEmhafWbqZArMuMrXz7g2jjTqkpE/31JLlco5P+PRqNhF1MFZFIpIhCIxBZ9HEw7SskrgasHY/B4pj5Z906A1OTLL78sKCggEP6tJMqv79+/j3W095qqcbcvVVeVSDx8zAzNdGwsI+0kFsmry0Tpx0qmrnKkG2lpi0Askv8Z+dpvqg3TlqrltVjzxEJZdZno8tGSr9Y5U+nw5iCE0OXLlzdt2sTlcuuXKBQKV1fXU6dOYZrrX5/8c3TrYnVdpXTweCsocKpCpuhZO9IiVnaMiSqUSbX08ZJDawomr3Sx60iHAvcxMpVo7WQwdbXrgdUw6c97/v7+HTp0aLiEQqFo1YTljde4mgpx1TtRvyBLjedpF4ZNtMlKrMI6RSNuXmD1H2MJJ2LNGjbR+rpWfoKYmDJlCp1Or//W2dl5zJgxmCb6j8b/N1e9EykU7XQKIg0wsSAXPOVhnaIRRc/4RtBsbwFjJrnwH238BDEREBBQP7oqmUyeNGkS1on+o/Eax62TWXSgajxMe8Ew0TdmksVCbblVXU+fomdiScY6hQ4wZpINGCSZTEsvOGheRESEsinn5OQUFBSEdZz/aLzGSURyifb9BuJJRZFACyfrrHwrVMi1LpV2KnujjZ8gVvz9/Z2cnEgkUkREBNZZPqSld/cAAOoj4MlKXgl4dVIeW4YUCh5H9vn7HN5zsR35OYXtlXai/DN3RSQS9IgEuhHRwIhkwtS37fhZXZSgxgHQXsikisfXa1884NVWiJkOdJmMQNQnEilkhVwFJ91Gph379OvI4asgJ0GB5HJZZblMJhETkKKmrNSlB72TJ8OpO70FW38IahwA+KdQKG6n1ty7XG3Z0djQxtSqmy5dbTdzlnEq+Pev8W5drBky3tzGuXXNOqhxAODc2xeCy8fKjSwZ3f10cm5Jkj7R1M4QIcSrEV4+XmXXkeo7sRWDqkNPKADw7MHVmqvxLKc+dkwXU6yzfC66KdWht61AQj0S9UYqaelNUahxAODW05vsl0/EHTxs9Ij4+U1nMA1sultFR75u4cNC+PnJAQAN5aSwcm8JLF2ZWAdRPQpd383Pee/3r+QtuFsCNQ4AHHr1mFvwVGTVBYcFrl6nAXZHfypqdjWocQDgDbtaci+DbeOmjaPyqhCFTjZ1MLkaX9n0alDjAMCbzIQqilFbupLpHEMm4/UTPuu/oxx+AGocALhSWSxilUiMrdvFKPwIIQsXs2uJrCZWUFn/uJmzwgoLX+vp6dHpDCcnl6E+/mPHfEkikepfUs7X6dDBKSBgTPDYCcrBV+vqaseF+H28t4z05icx4/F466N++PWXXZ+f3Nmp45off2rDtmVlpQqksLHWlqmsNS8h4WRC4qny8lJDQ6OBA3y+W7aq6fW37/gl81p6QtwlTQVsBv4+wQeZteZa2U2kivX2520TIkI3eLqrcnJuQwuDqjpeWaHA2qnxvsGq7ANsY207ZsyXXC7n7t2cnbu2PHhwZ0PUbw1fkkgkjx7d27lry527NzdG/V4/xvQXvb3d3Xu39nAZVy/duZvzrqTYztZehT9Fy70rKZ46bfyaH3/C029IqyQmndm5+7ehPn5jgkIKCl+x2XVYJ2od/H2Ccpni5T2Omz+ebzU0gqif/4inkRpnYzdp4nSE0JzZ36yPiryamVZY+NrJyaXhS2jq7MSkM9t3/BIXfzw8bKpyQ3f33tOmzm7t4S4kJ5LJ5PT0i23YViVkUmnTs2Hg3qXLF1w7dl675mflt5p/NxQKRUnpuzb/kcPfJ/g6l2dqa4B1Ck0ztDR49bhiUHDjlV1dz3L17zf4amZaZVWFssY1NC449PyFhL8TT9XXuDZ4/To/P/95xOSvLqclN6xxY4KHLlm8IisrI+dWFp3OGBP05fRpcxBCYrH4r9j9V66kVlSWm5szR/iPnjH96w8mKxGJRBNCAwIDx82ft0S55F1J8ZSp4yK/X+fj47dtx883blxDCLm7e36zYLkCKabPnIAQWh8VuR6hgICgyO/XtfnH0VEikZBC+ffJx4ZjDT14ePfgoT35+c+Z5hYhIZMOH967e9cRBwenFu75yZOHsUcPPMl9iBDq2sVt3rwlXTp3U770T17u7j2/v3790tyM6eTcMT//+V9HEshkslAoPHBwd/qVi2KxqIO9Y1jY1OHDRiCE4uKPX8m4FDoh4uDB3azqqk6dui5fttrBwam0rAR/n2DJKwGdqa67DTdux2dmH69jV5iZ2nq6jxg6cIq+PuVdyfNdB+bMmro1+dKekrIXpiY2o0d806PbEOUmXF5NUvLWp8+u6ZMoHZ3VNcM0hU6mGerXVIhNGxv9UF33HF4X5COEmOaNP1bm6dGnvLyMxXo/WjSfz6uoKFf+azj5RROSU5K8vPqNGDG6uLgo79nThi/9/MtaV9cu27bu9/cLPBITnZOThRAiEon37t3qP2DI/HlLe3t6Hz12KD7hxAf7pFAovr4j069clMneDzWTmZlGoVAGDRp2/MTh1NTzE76c/PXcb9nsOhqNZm7GXLVyI0Jo5ox5O7YdmDL5qza9T7rNu8+AvLzcEydjpNL/TNx3/8Gd/32/kMvlzJm9aOLE6ecvJHB5LfpY65WVlYjEoqlTZk+fNresrCRyxbdCoRAhVF5etvx/80kk0qoVGz09+2RnZ44dM4FMJsvl8lWrl968eS1i8sylS1a6unbZsHFlckqScm95ebmnT8d+993qqPW/VVaU//TLWoQQLj/Bsjcikr5aJuK4dGX/hdRdHj39w8atdnfzvXr9aFzS+0vYEono6KlVQwZMnP/VXlMT6+NnfuTxahFCEqk4+siip3mZQwZMHh3wTXVNiTqCKQkF8k/NHqnKdhyfzyssfM3n827fuRGfcMK1Y+ePG3FKJiamCCE2u87MzBwhdOp07KnTscqXpkR8NeurBU0fSCKRpKWnzP96ia2NnbNzx7T0lG5d3epfDRwVHDF5JkLItWPnC8mJt+/e7NdvEJFI3LM7pr6hUVJafO36lbDQD2fWCAgYk3Q27s7dnH59ByprXP9+g+l0emlZCY1GmzxpBolEGh04Trly505dEUIODk49e3p8xtumw2ZM/7qkpPjP/TvPnYufNm1OwIgg5TscHb3dyMh4984jyrFhGQzD9VGRrdqzn98of/9A5dddunRf9t28J7kP+3j1u5yWLBAI1v74s5mZ+cCBPo8e38+5lTV50oxr1688fvLgxLFzTKYFQsjPd6RAwI9POBE4Kli5k00btyr/s4WETNyzd2sdu87YyBh/nyCfIzPuoPoaV8euTL92JGLCBvcew5VLjA2Z8ed+CQ5cpvx23OjvPHr6I4QC/Rds2zv9VeEDd7dh2TlnSstezp2+s7OrN0LIqUPPX3eEqzybEolM4tWpv8Y9e/7PzFlhyq+7deuxetWmTw2UWldXixCiUN+f5vj5jRo+9P2tFju7Do1u0lBW9lUejztgoA9CaED/IReSE+d/vUR5DxchRKW+v/RIJBItLCxZVe+7CNbUVP8Vu//O3RwOh40QMmQYfrznbl3dnJxcLl0636/vwJLSdy9ePps6dTZCyM93VHr6xR8iFy1c8J2Li2vr3xt8olAo69f9+vDhvcMx+375dX1W9tX1a3/l8XkvXj4LC/3PPCatRSAQrmdlnD5z9M2bAgMDA4RQTTULIVRZWU6n05XVikAg2Nral5eXIoRycrKkUunkKWPr9yCTyej0f/tP1P+vsLKyQQixqiqNjYw/76fXRmKhnERR/QWol69uy2TSY3FrjsWt+f9lCoRQHadC+Q1Z//3ba2pigxBicyoRQrl5mTZWrsoChxDS01PjTG96ZKKAo/4a17lT12lT5xCJRHt7B3t7hybWLC19RyKRmOYWAgEfIdTB3rF//8EtP1BKSlLv3t40Kk0qlfbrO+jY8cN3791Strw+QCKSZHIZQqi6mjV3XgSNZvDVzPm2tvaHDu15W/ym0Z2PGjn24KE9HC4nMzONQWf09R6IEOrrPeCnzdv3RW+bNWfi6MBxSxZH1pdU4OHxxXaP/X/FHjh8ZN+Nm9dcXDohhCwsPmtSN+XevgyZNHf2IlZ11fqoSLlCrvwTyOPxXr/Od3FxlUgk+fnPPTy8EEI1NSxzc+Yfv+1ruBNiY5+RPkkfIaT8X4E/CpkCqeEuCptThRCaNeUPE+P/fKzmZvZl5a8aLiER9RFCcrkMIVRbV2Zn00XlYRqnQOgTLSpV/qIyGIYDB/o0u1pNTfXtOze6detBJpOVNa5VyspK7967pVAo/AP61S9MT09ptMbVO3suvqamevfOI1ZW1gghS0vrT9U4f7/AP/fvzMi4lJmZNmSIr77++3mq+noP6OPVLz7hxJ69W62sbKZOmdXa5PgWHjb18JF9L17k9fHqjxCqqmrmCZsmiESi4ycOjw4c983C7xBCFRX/jp0dMCLoTNyxlauXjPAf/fDRPalUOmPaXISQoaFRbW2NlZUNhUJR0Q+kk6gMolQsI6r6khyNZqT8wtKipXeNEEIMuimXV6PaJJ8il0gNjBr/6DX9nINMJtu99w+xWBwyfmLb9nAx9SyRSNy5/eDePX8p/40OHJeVfZXPb6pcstm1JiamygKHEKpj19Z3GiDrk5Vnr0qmpmb9+g06dTr2+Ys8X9+RyoVisRghpKenFzohgsm0ePnyGUJIeUuR9Rm/zLqOy+XK5e+H8Xr16gVCiEYzoFKpTk4u6VcuCgSCjzfR1ycLBPwP7lF8QCgUiESizv9/I7WOXYsQUh7I2Njkm4XLKRRqQcErry/67Y8+rjxj6N3bWyaTnT0XV7+TRo/+Afx9ggaGRKlI9U3UTi5eBAIh69bp+iUicfNvr51Nl7fv/qmobLwxoVoysYxu1HiLTUMnXO9K3h46vFcikeTcyiosfB00evxQn0Yeb2iWXC6/mHqul3vvHj161S8UCPgXkhOzsjJGjBj9qQ09PLz+Tjx96PBeN7de169fuXUrWy6X19XVGhubuLp2SU5J2r3nj7lzFilbbb7DR0ZtWGFuzvTo9f5ud8LfJ7NvZPr7BbJYlVVVlV26dEcIWVpa2drYnY47SqXR2Oy6kPET21sj4q/Y/Tdzrvfx6kfQ07t86YKRkfEI/9EIoWlT50RtWLFw0Yyg0SH6+vrJyYn1m3Ry7SIUCtdF/TB/3tJP9WszNjZxcXFN+PukmZk5j8uN+etPPT2916/zEUJ5z57+umX9t998T9LX19PTKy19Z2ZmTiQS/f0Cz51P2Be9vbSspHOnrvn5L7KyM44ciqNSmxrU+4NPMHRChK5fgrB2orKqVV/jmOYdBvULv37z5KGj37l18+FwqrJvxc2a+oe9bdcmtho2eNrdh8l7Ds0b0n+ikSHz/uNUlQerp08mGJk3PjWwhtpx5eVlR48dSk5JsmBarl3zc7NP/HzKvfu3y8vLBvQf0nBhzx4eBgYGaekpTWw4ZPDwaVNnJyad2bRplUQqUfbV+jvxFEJo9qyFgwcNu3jxrEj0/sne7t16IoSGDR2hp/f+/bG1tZeIxXv3bb2QnBgSMlHZs49AIKxevdnAgL5r928XU8/V1FS37YfSXS4urmQyOeXi2czMtD59+u/ZHaO8rTlsqP+ypStFItHefVtPnfrL0tK6fhNf35FhoVOePXtaWPCqiT3/uGozjUqL2rDi1JnY+fOXTp0yKzX1nEQisbaysbGx+2XL+o2bVkVtWLF46Zz5C6YJhUJ9ff0tv+wOGj3+ypXUP7Zuvv/g9tgxE5otWB98gvzWXznRNvauNF5V67rptNDYUUvGjPy2tPxVwrlfbt1L6tF9qLFRM5dcmeb2c6ZtNzGyTL2y//LVQ7ZWndQRDCEk5IilIpnxJ2ocodF+3rdTq8VC1GuomZoyablXr17Onjtp756/unbprqZDHN/86qsoF32Kdk3QGf3Dq9DvVJ/qamba+qjImMNxLe8D3ASZTKbsvC2Tya5nZayPivz9t729PfuoImkr/BWVP3+Lq572DWqxa2m+m79Tu5r7tfJ1jb0Tof9o80Zf1dKW+bdLZhcU5H+8fMAAnxU/rFffccvLy5LOnklOSfL08FJfgQPKa3mTIhqfUP3ruYuDRo9v9KWiosLFS+f07zfYtWNnkVh07Vo6lUq1t2vqJn57062vMZfFN/z00w7nL+7MuZf48XJ7m67Fpc8a3WTRnANWliqb7yb58p4bt+M/Xq5PokikjY+S9OPycxTKJ59RU0ilrr1MPvWqlta4Nat/kkglHy+nUT9rNtlmFb0tvHT5gq/vyFkzm+mHDD6TgYHBn9HHG33JyPCTPdfodIbv8JE5OdcvpyUzGIY9e3gsWbLC0hLng0G2Su/hxn/vLm2ixg0bMm1A3y8/Xk4gNH5WhxBq9rS0VXwGRvTzGvfxcqlUQiI1fr5JJn/yF7+unEczUFjYf/LCq5bWOOVlHc3r49Uv7vRFTA6NY0N9/IZ+NFiWnp5eG0b7MDdnfrPwO2WfEtAoU0uynSu15h1HOV/fx+gGxnQDLPs/qzZA5avq0CV2TaygfZcTAACfxyfEXMLlYZ1CEzgVnO59GZ+626AENQ4AvKHSSQODzIoflWIdRL34tUI+izsgqJnB8qDGAYBDdq40t370d7nlLVhXJ0lE0qIHZeHLmh86EGocAPjkOdS0b4BxaR4Oyxy/VpifXfz1L40Pa/QBqHEA4JarO91zCKPgdrFE2NTDc7qFXcFlv6uev6VjC/sAaul9VQCASnT1MrKwo6TElJMNKObOZkSSDjdr2BW8qtc1XbwYY6c3PwJbPahxAOCcuQ1lSqTDk6y6rLNFprZ0A1MDI0tdmn1VxJOwK3kEqUSfrBi/0KbRAc2bADUOgHah5yDjnoOM826zn9/n5l6qsHCky2WISCbqU8lyuXZN3EMgEGQSqUwik4llBD2FmC/t6E7v5GH8qZm3mgY1DoB2pJu3UTdvI4TQu5d8LlvGZ0tlUrmAK8c613/oERFJn0A3otKNScZMkpn1Zw3nAzUOgPbIrlN7maKw8RpHphLkqB2NW6B5lg405fDMWAf5D0sHGkFP61JpJxsnmkIB75UOaPwmi6GpfuWb5sf5BG3DqZZwqsX6FK27wyUVy6vLGh/4ATRUWyES8GREIhQ4HdD4r5llB0p7Gn5K02oqRM49tfHGlmM3AzZLjHUKHVBbIXbu0V7O9XTdJ9txdq7Ua/FlGs+Df1KJPONU2eBx2Ays0jTvkWYP0qtrK6Ep1xQBV5qdVN7sY5JAS3xyxCiE0NObdS8fcnv5mJtakXW666CW4NZKaspEGafL5mxyIVO19P2UyRQHVr8eEGRpZksxMmtdRyTc49RIaspF1+LKZ29y1idr6ScIPtBUjUMIFTzlPcysLSsQEklw7vpZrByoNRXijr3o2tmC+8CNc1X5j3hGZvoVb4VYZ9EWVo602kpRx170QWN14BME9ZqpcfVEAu3qQaN7FAqKgRrnCVcHsVCuhvmIdRUBITIN2m66p6U1DgAAdBH8XQIA4BnUOAAAnkGNAwDgGdQ4AACeQY0DAOAZ1DgAAJ79Hw2KLTtqFdvKAAAAAElFTkSuQmCC",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(research_graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8v_rjTN3G3pC",
      "metadata": {
        "id": "8v_rjTN3G3pC"
      },
      "source": [
        "# Research Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "TbAqLq_oG3AZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbAqLq_oG3AZ",
        "outputId": "20178231-2994-4606-a646-83a696f09d15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'supervisor': {'next': 'PDF_Analyst'}}\n",
            "----\n",
            "{'PDF_Analyst': {'messages': [HumanMessage(content='I am sorry, I cannot answer this question. I do not have access to a database of refrigerator dimensions.  The provided API does not allow me to retrieve this information.', additional_kwargs={}, response_metadata={}, name='PDF_Analyst', id='6d0e6c8f-03c6-4cf1-aefa-2ff3b38ae94f')]}}\n",
            "----\n",
            "{'supervisor': {'next': '__end__'}}\n",
            "----\n"
          ]
        }
      ],
      "source": [
        "query = \"What are the Dimensions and Volume of the 27.8 Cu. Ft. French Door Refrigerator?\"\n",
        "\n",
        "input_data = {\"query\": query}\n",
        "\n",
        "for s in research_graph.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            HumanMessage(content=input_data['query'])\n",
        "        ]\n",
        "    }\n",
        "):\n",
        "    if \"__end__\" not in s:\n",
        "        print(s)\n",
        "        print(\"----\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "0kwnsQti4I4k",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kwnsQti4I4k",
        "outputId": "2a826228-02a8-43d9-b809-a6d22fc0a330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'supervisor': {'next': 'Sql_agent'}}\n",
            "----\n",
            "{'Sql_agent': {'messages': [HumanMessage(content='The number of sales per country are as follows: Australia - 1964, Canada - 1963, India - 2071, UK - 2037, USA - 1965.', additional_kwargs={}, response_metadata={}, name='Sql_agent', id='b0e9a6c5-e6ce-493c-9c79-b7b372c4aa77')]}}\n",
            "----\n",
            "{'supervisor': {'next': '__end__'}}\n",
            "----\n"
          ]
        }
      ],
      "source": [
        "query = \"How many sales are there in the database per country?\"\n",
        "\n",
        "input_data = {\"query\": query}\n",
        "\n",
        "for s in research_graph.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            HumanMessage(content=input_data['query'])\n",
        "        ]\n",
        "    }\n",
        "):\n",
        "    if \"__end__\" not in s:\n",
        "        print(s)\n",
        "        print(\"----\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "N1vN9ozP2jBh",
      "metadata": {
        "id": "N1vN9ozP2jBh"
      },
      "source": [
        "# Initialize the Writing Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "a5vb-dBO2DuU",
      "metadata": {
        "id": "a5vb-dBO2DuU"
      },
      "outputs": [],
      "source": [
        "def call_model(state: MessagesState):\n",
        "    # add any logic to customize model system message etc here\n",
        "    response = llm.invoke(state[\"messages\"])\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "builder_writer = StateGraph(MessagesState)\n",
        "builder_writer.add_node(call_model)\n",
        "builder_writer.add_edge(START, \"call_model\")\n",
        "\n",
        "writer_graph = builder_writer.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "O5IIhlm02jAm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "O5IIhlm02jAm",
        "outputId": "66db4225-1b2c-4324-883b-6b4420c8e6b6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "from langchain_core.runnables.graph import MermaidDrawMethod\n",
        "\n",
        "display(\n",
        "    Image(\n",
        "        writer_graph.get_graph().draw_mermaid_png(\n",
        "            draw_method=MermaidDrawMethod.API,\n",
        "        )\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "ON-MlQ852jU6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ON-MlQ852jU6",
        "outputId": "cd145b8a-4735-48cf-f1e2-f8e24717b6a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'call_model': {'messages': [AIMessage(content=\"Describing an LG refrigerator depends on the specific model, as LG offers a wide range of styles, features, and sizes. However, some common characteristics across their lineup include:\\n\\n**General Design & Features:**\\n\\n* **Sleek and Modern Aesthetics:** LG refrigerators are generally known for their clean lines and modern designs, often featuring stainless steel finishes, although other colors are available.  They tend to have a more contemporary look compared to some other brands.\\n* **Variety of Styles:**  LG offers various styles, including French-door, side-by-side, top-freezer, and bottom-freezer models.  They also offer some unique styles like InstaView Door-in-Door models.\\n* **Space-Saving Features:** Many models incorporate features designed to maximize storage space, such as adjustable shelves, door bins of varying sizes, and specialized compartments for specific items (e.g., crisper drawers for fruits and vegetables).\\n* **Technological Advancements:** LG often incorporates advanced technologies into their refrigerators, such as:\\n    * **Door-in-Door:** Allows quick access to frequently used items without opening the entire refrigerator, saving energy.\\n    * **InstaView Door-in-Door:**  A feature where a double-knock on the door illuminates the interior of the Door-in-Door compartment, allowing you to see inside without opening it.\\n    * **Smart Features (on select models):**  Connectivity to Wi-Fi, allowing for remote temperature control, diagnostics, and even inventory management through a smartphone app.\\n    * **Linear Compressor:**  A type of compressor that LG often uses, claimed to be more energy-efficient and quieter than traditional compressors.\\n    * **Ice Makers:**  Most models include an automatic ice maker, often with options for crushed or cubed ice.\\n* **Energy Efficiency:** LG refrigerators generally aim for high energy efficiency ratings, helping to reduce electricity bills.\\n\\n\\n**Things to Consider When Choosing a Specific Model:**\\n\\n* **Size and Capacity:**  LG offers refrigerators in a wide range of sizes to fit various kitchen spaces and family needs.\\n* **Features:**  The specific features available will vary greatly depending on the model and price point.  Consider which features are most important to you (e.g., ice maker, smart features, specific storage compartments).\\n* **Price:**  LG refrigerators range in price from budget-friendly options to high-end models with advanced features.\\n\\n\\nIn short, an LG refrigerator is likely to be a stylish, technologically advanced appliance with a focus on energy efficiency and convenient features.  However, the specifics will depend entirely on the particular model you are considering.  Checking LG's website or a retailer's website for detailed specifications is crucial before making a purchase.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-ac2fea58-98c3-41d6-8af0-8d2e9e617d68-0', usage_metadata={'input_tokens': 9, 'output_tokens': 567, 'total_tokens': 576, 'input_token_details': {'cache_read': 0}})]}}\n",
            "----\n"
          ]
        }
      ],
      "source": [
        "query = \"Describe an LG refridgerator?\"\n",
        "\n",
        "input_data = {\"query\": query}\n",
        "\n",
        "for s in writer_graph.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            HumanMessage(content=input_data['query'])\n",
        "        ]\n",
        "    }\n",
        "):\n",
        "    if \"__end__\" not in s:\n",
        "        print(s)\n",
        "        print(\"----\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yavrq57Ff_uy",
      "metadata": {
        "id": "yavrq57Ff_uy"
      },
      "source": [
        "# Add Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "tHZ-fcGAf-ke",
      "metadata": {
        "id": "tHZ-fcGAf-ke"
      },
      "outputs": [],
      "source": [
        "prompt_message_super=\"\"\"You are a supervisor tasked with managing a conversation between the following workers: {{members_super}}.\n",
        "Given the following user request, respond with the worker to act next. Each worker will perform a task and respond with their results and status. If the conversation is over, respond with 'FINISH'.\n",
        "\n",
        "Create a nicely formatted overview of the LG refridgerator. Make sure to adhere to the following:\n",
        "        1. LG sales per country from the database\n",
        "        2. Most comment features of the refridgerator \n",
        "\n",
        " \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "52dfBhVPQH1r",
      "metadata": {
        "id": "52dfBhVPQH1r"
      },
      "outputs": [],
      "source": [
        "teams_supervisor_node = make_supervisor_node(llm, [\"research_team\", \"writing_team\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "USBSaVQDgyO9",
      "metadata": {
        "id": "USBSaVQDgyO9"
      },
      "outputs": [],
      "source": [
        "def call_research_team(state: AgentState) -> AgentState:\n",
        "    response = research_graph.invoke({\"messages\": state[\"messages\"][-1]})\n",
        "    return {\n",
        "        \"messages\": [\n",
        "            HumanMessage(content=response[\"messages\"][-1].content, name=\"research_team\")\n",
        "        ]\n",
        "    }\n",
        "\n",
        "\n",
        "def call_paper_writing_team(state: AgentState) -> AgentState:\n",
        "    response = writer_graph.invoke({\"messages\": state[\"messages\"][-1]})\n",
        "    return {\n",
        "        \"messages\": [\n",
        "            HumanMessage(content=response[\"messages\"][-1].content, name=\"writing_team\")\n",
        "        ]\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "8IxNnLZQgyRa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IxNnLZQgyRa",
        "outputId": "9d6d6cab-8e16-4401-e490-447945e186c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x24f1d13d610>"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define the graph.\n",
        "super_builder = StateGraph(AgentState)\n",
        "super_builder.add_node(\"supervisor_super\", teams_supervisor_node)\n",
        "super_builder.add_node(\"research_team\", call_research_team)\n",
        "super_builder.add_node(\"writing_team\", call_paper_writing_team)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "EswBiBjegyT7",
      "metadata": {
        "id": "EswBiBjegyT7"
      },
      "outputs": [],
      "source": [
        "# Define the control flow\n",
        "super_builder.add_edge(START, \"supervisor_super\")\n",
        "# We want our teams to ALWAYS \"report back\" to the top-level supervisor when done\n",
        "super_builder.add_edge(\"research_team\", \"supervisor_super\")\n",
        "super_builder.add_edge(\"writing_team\", \"supervisor_super\")\n",
        "# Add the edges where routing applies\n",
        "super_builder.add_conditional_edges(\"supervisor_super\", lambda state: state[\"next\"])\n",
        "super_graph = super_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "ImsNXPxAgyWw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "ImsNXPxAgyWw",
        "outputId": "9c955a6d-c5ac-4f54-c86e-37999f1d19ae"
      },
      "outputs": [],
      "source": [
        "#from IPython.display import Image, display\n",
        "\n",
        "#display(Image(super_graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "a-WWqObBgyZg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-WWqObBgyZg",
        "outputId": "5a3ca9e9-473f-4cf7-cf92-64824f1f7f0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'supervisor_super': {'next': 'research_team'}}\n",
            "---\n"
          ]
        },
        {
          "ename": "ChatGoogleGenerativeAIError",
          "evalue": "Invalid argument provided to Gemini: 400 Unable to submit request because it has an empty text parameter. Add a value to the parameter and try again. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/gemini",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:178\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:835\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    834\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 835\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    208\u001b[0m         error_list,\n\u001b[0;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    210\u001b[0m         original_timeout,\n\u001b[0;32m    211\u001b[0m     )\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\google\\api_core\\timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
            "\u001b[1;31mInvalidArgument\u001b[0m: 400 Unable to submit request because it has an empty text parameter. Add a value to the parameter and try again. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/gemini",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mChatGoogleGenerativeAIError\u001b[0m               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[102], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msuper_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_message_super\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecursion_limit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m---\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1670\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1664\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1665\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[0;32m   1666\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1667\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1668\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[0;32m   1669\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1670\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1672\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1673\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1675\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1676\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[0;32m   1677\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1678\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:230\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    228\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:462\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    458\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m    459\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    460\u001b[0m )\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 462\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:226\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    225\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 226\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "Cell \u001b[1;32mIn[99], line 2\u001b[0m, in \u001b[0;36mcall_research_team\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_research_team\u001b[39m(state: AgentState) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AgentState:\n\u001b[1;32m----> 2\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mresearch_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m      5\u001b[0m             HumanMessage(content\u001b[38;5;241m=\u001b[39mresponse[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresearch_team\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m         ]\n\u001b[0;32m      7\u001b[0m     }\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1961\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   1959\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1960\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1961\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1962\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1965\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1966\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1967\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1969\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1970\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1971\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1670\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1664\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1665\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[0;32m   1666\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1667\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1668\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[0;32m   1669\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1670\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1672\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1673\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1675\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1676\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[0;32m   1677\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1678\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:230\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    228\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:462\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    458\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m    459\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    460\u001b[0m )\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 462\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:226\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    225\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 226\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "Cell \u001b[1;32mIn[81], line 31\u001b[0m, in \u001b[0;36mmake_supervisor_node.<locals>.supervisor_node\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"An LLM-based router.\"\"\"\u001b[39;00m\n\u001b[0;32m     28\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     29\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: system_prompt},\n\u001b[0;32m     30\u001b[0m ] \u001b[38;5;241m+\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 31\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_structured_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRouter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m next_ \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mnext\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m next_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFINISH\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3014\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3012\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m   3013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3014\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3015\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3016\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5352\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5347\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5348\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   5349\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5350\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5351\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5353\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5354\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5355\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5356\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:284\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    280\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    281\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    283\u001b[0m         ChatGeneration,\n\u001b[1;32m--> 284\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    294\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:791\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    785\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    789\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    790\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:638\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    636\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    637\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 638\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    644\u001b[0m         )\n\u001b[0;32m    645\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    646\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:856\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 856\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    860\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:951\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._generate\u001b[1;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate\u001b[39m(\n\u001b[0;32m    926\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    927\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    938\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    939\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[0;32m    940\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[0;32m    941\u001b[0m         messages,\n\u001b[0;32m    942\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    949\u001b[0m         tool_choice\u001b[38;5;241m=\u001b[39mtool_choice,\n\u001b[0;32m    950\u001b[0m     )\n\u001b[1;32m--> 951\u001b[0m     response: GenerateContentResponse \u001b[38;5;241m=\u001b[39m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:196\u001b[0m, in \u001b[0;36m_chat_with_retry\u001b[1;34m(generation_method, **kwargs)\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m--> 196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:336\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    334\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    335\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m--> 336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:398\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[1;32m--> 398\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\frede\\OneDrive\\Documents\\GitHub\\agentic-langgraph\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:190\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    192\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
            "\u001b[1;31mChatGoogleGenerativeAIError\u001b[0m: Invalid argument provided to Gemini: 400 Unable to submit request because it has an empty text parameter. Add a value to the parameter and try again. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/gemini",
            "\u001b[0mDuring task with name 'supervisor' and id 'c51113cc-68d2-8287-1335-4f120fdbe993'",
            "\u001b[0mDuring task with name 'research_team' and id '933d64a8-0b0d-1504-5169-b5c23f5ad96b'"
          ]
        }
      ],
      "source": [
        "for s in super_graph.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            (\"user\", prompt_message_super)\n",
        "        ],\n",
        "    },\n",
        "    {\"recursion_limit\": 25},\n",
        "):\n",
        "    print(s)\n",
        "    print(\"---\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "AgenticAI_LangGraph_Hier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
